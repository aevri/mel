#! /usr/bin/env python
"""Pre-train 'automark2'."""

import argparse
import gzip
import pickle
import sys

import cv2
import torch
import torchvision

from tqdm import tqdm

import mel.rotomap.moles
import mel.lib.common
import mel.rotomap.detectmolesnn


def setup_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "IMAGES", nargs="+", help="A list of paths to images to process."
    )
    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Print information about the processing.",
    )
    return parser


def main():
    parser = setup_parser()
    args = parser.parse_args()

    for path in tqdm(args.IMAGES):
        outpath = path + ".automark2.pt.gz"
        if args.verbose:
            print(outpath)
        zipout = gzip.open(outpath, "wb", compresslevel=6)
        x_data, y_data, m_data = rotoimage_to_xym_tensors(path)
        x_data = mel.rotomap.detectmolesnn.pixelise(x_data)
        y_data = mel.rotomap.detectmolesnn.pixelise(y_data)
        m_data = mel.rotomap.detectmolesnn.pixelise(m_data)
        x_data = mel.rotomap.detectmolesnn.select_not_masked(x_data, m_data)
        y_data = mel.rotomap.detectmolesnn.select_not_masked(y_data, m_data)
        x_data, y_data = mel.rotomap.detectmolesnn.shuffled_images_sync(
            x_data, y_data
        )
        # As you might hope, this only saves about 2x space when compressed.
        # x_data = (x_data * 255).type(torch.uint8)
        # y_data = (y_data * 255).type(torch.uint8)
        x_data.rename_(None)
        y_data.rename_(None)
        data = {"x_data": x_data, "y_data": y_data}
        torch.save(data, zipout, pickle_protocol=pickle.HIGHEST_PROTOCOL)
        zipout.close()


def rotoimage_to_xym_tensors(path):
    to_tensor = torchvision.transforms.ToTensor()

    photo = mel.lib.image.load_image(path)
    mask = mel.rotomap.mask.load(path)
    photo_hsv = cv2.cvtColor(photo, cv2.COLOR_BGR2HSV)
    blur_photo = cv2.blur(photo, (64, 64))
    blur_photo_hsv = cv2.cvtColor(blur_photo, cv2.COLOR_BGR2HSV)
    blur_mask = cv2.blur(mask, (64, 64))
    x_data = torch.vstack(
        [
            to_tensor(x)
            for x in [
                photo,
                photo_hsv,
                blur_photo,
                blur_photo_hsv,
                blur_mask,
            ]
        ]
    )

    moles = mel.rotomap.moles.load_image_moles(path)
    image_height, image_width = photo.shape[0:2]
    locations_image = mel.rotomap.detectmolesnn.locations_image(
        moles, image_width, image_height
    )
    y_data = to_tensor(locations_image)
    y_data = y_data[2:3].clone()
    assert y_data.shape[0] == 1, y_data.shape

    m_data = to_tensor(mask)
    assert m_data.shape == y_data.shape, m_data.shape

    return (
        x_data.rename(*list("CHW")),
        y_data.rename(*list("CHW")),
        m_data.rename(*list("CHW")),
    )


if __name__ == "__main__":
    sys.exit(main())
